{"ast":null,"code":"var logotext=\"Yuzhuo Jia\";var meta={title:\"Yuzhuo Jia\",description:\"I'm Yuzhuo Jia\"};var introdata={title:\"Yuzhuo Jia\"//   animated: {\n//     first: \"[]\",\n//     second: \"[]\",\n//   },\n//   description:\n//     \"In the past, I was a Research Assistant at the KAIST Interaction Lab (KIXLAB) developing a Generative Agent for Programming Education. My research interests are at the intersection of Human-AI Interaction and applied Machine Learning.\",\n//   description_two:\n//     \"  I am currently a first year Computer Science (MS) student at Stanford and I did my undergrad at Cornell studying Information Science. I have received grants and scholarships for my research like the Robert S Ann Morley Research Grant and the Gwanjeong Scholarship for my Master's Studies.\",\n//   your_img_url: \"\",\n};var dataabout={title:\"Research Interests\",aboutme:\"My research interests focus on interdisciplinary studies, with a particular emphasis on exploring how deep learning, computer vision, or LLM technologies can be integrated with diverse fields. I aim to develop innovative, socially conscious research and tools that not only contribute to academic advancement but also address real-world societal challenges. My goal is to harness the power of AI to create solutions that are both technologically advanced and ethically responsible, ensuring their positive impact across different communities and disciplines.\"};var worktimeline=[{jobtitle:\"University of Sydney\",where:\"Computer Science (MS)\",date:\"Feb 2023 - Mar 2025\"},{jobtitle:\"Nanfang College of Sun Yat-sen University\",where:\"Computer Science and Technology (BS)\",date:\"Sep 2017 - June 2021\"}];var skills=[{name:\"Python\",value:90},{name:\"Djano\",value:85},{name:\"Javascript\",value:80},{name:\"React\",value:60},{name:\"Jquery\",value:85}];var services=[{title:\"SDG AI Lab - Software Engineer\",period:\"March 2023 - May 2023\",description:\"Development of the Digital Technologies Radar : a Frontier Technology Radar for Disaster Risk Reduction (FTR4DRR), which allows for the systematic tracking and understanding of frontier technologies as they are developed. https://github.com/SDG-AI-Lab/Digital_Technologies_Radar\"},{title:\"Inspirit AI - AI/ML Instructor\",period:\"March 2020 - \",description:\"Conducted lectures on Neural Networks, Computer Vision, Deep Learning, Reinforcement Learning and helped highschool students work on programming ML Models\"},{title:\"Cornell Data Science - Insights Team\",period:\"Janurary 2020 - December 2022 \",description:\"Insights Team - Conducted and led Data Science/Machine Learning Projects, Conducted lectures on Neural Networks for Freshman Onboarding INFO 1998 ML lectures \"}];var awards=[{title:\"Gwanjeong Educational Foundation Scholarship - Masters Degree\",period:\"Sep 2023 - June 2025\"},{title:\"ACM/IEEE Human Robot Interaction (HRI 2023) - Best Student Paper Award\",period:\"March 2022\"},{title:\"Robert S Ann Morley Research Grant - Cornell University\",period:\" December 2021 \"}];var workexperience=[{title:\"[Motional] Robotics Research Engineer\",period:\"Sep 2022 - Dec 2022\",description:\"Research on identification of Autonomous Vehicle Lane Change key parameters and metrics in dynamic road environments interacting with other agents. Published and first authored 2 papers to ACM/IEEE HRI 2023\"},{title:\"[Harvard Berkman Klein Center] Software Engineer\",period:\"May 2023 - August 2023\",description:\"Developed Software for dynamic text annotation and page navigation on H2O, an open-casebook platform (React, Django). Conducted Research on Digital Reading Interaction Software and published paper to ACM/IEEE CHI 2023\"},{title:\"[Cochl. AI] Software Engineer\",period:\"Nov 2020 - Feb 2021 \",description:\"Integrated non-verbal sound recognition AI into Mercedes Benz User Interface. Full-stack development using React, Javascript, SocketIO, Docker. Developed and demonstrated a working prototype of Emotional Sound Recognition within Benz Cars to the Mercedes Benz Team - Presentation at Benz conference in Germany\"}];var researchexperience=[{title:\"BiFocalNet: Dual-Branch Architecture for Enhanced Remote Sensing Segmentation\",period:\"Sep 2023 – Jul 2024\",description:\"Developed BiFocalNet, a deep learning architecture for remote sensing segmentation, achieving a 3.062% improvement in mean IoU on the GID dataset. Designed a parallelized encoder combining EfficientNetV2 and Pyramid Vision Transformer, integrated via Cross-Fusion and SuperASPP modules for enhanced multi-scale context modeling. Demonstrated superior performance in key categories, with 3.279% and 3.514% improvements in 'Forest' and 'Built-up' segmentation.\"},{title:\"FODAP Graph for Enhanced Medical Imaging Narrative Generation\",period:\"Mar 2023 – May 2024\",description:\"Co-designed a MedSAM-based visual encoder with Vision Transformer (ViT) architecture, processing 512x512 medical images for high-quality feature representation. Simplified model by removing the MLP neck and optimizing patch embeddings. Implemented a feature reduction strategy to improve generalization across datasets. Conducted comparative experiments, showing MedSAM's superior performance in medical imaging, and contributed to the Graph-Enhanced Attention (GEA) mechanism for more accurate medical report generation.\"},{title:\"A Study on Corn Pest Detection Based On Improved YOLOv7\",period:\"Dec 2023 – Mar 2024\",description:\"Developed SPD-YOLOv7, an enhanced model for corn pest detection with 98.38% accuracy, 99.51% recall, and 99.4% mAP@0.5, outperforming YOLOv7. Introduced SPD-Conv to improve small object detection and ELAN-W with CBAM attention for better feature extraction in complex backgrounds. Conducted ablation experiments to validate model improvements, especially for small pest detection.\"}];var dataportfolio=[{img:\"BiFocalNet\",title:\"BiFocalNet: Dual-Branch Architecture for Enhanced Remote Sensing Segmentation\",authors:\"Yuzhuo Jia\",conference:\"IEEE Transactions on Geoscience and Remote Sensing\",//doi: \"https://doi.org/10.48550/arXiv.2408.10240\",\n//video: \"https://www.youtube.com/watch?v=tJUqjjwSxPs\",\nnotes:\"Under Revision\",code:\"Code Coming Soon\"},{img:\"bibm1\",title:\"FODAP Graph for Enhanced Medical Imaging Narrative Generation: Adaptive Differentiation of Normal and Abnormal Attributes\",authors:[{name:\"Kai Shu\",bold:true},{name:\"Yuzhuo Jia\",bold:true},{name:\"Ziyang Zhang\",bold:false},{name:\"Jiechao Gao\",bold:false}],conference:\"International Conference on Bioinformatics and Biomedicine (BIBM 2024)\",doi:\"https://www.arxiv.org/abs/2409.03947\"},{img:\"yolo5\",title:\"Pedestrian behavior detection and traffic violation recognition based on YOLOv5\",authors:\"Yuzhuo Jia\",conference:\"International Conference on Image Processing and Intelligent Control\",doi:\"https://doi.org/10.1117/12.3038591\"}];var projectportfolio=[{img:\"paper\",title:\"Paper Review Assistant\",description:\"Developed a Next.js web app utilizing AI for academic paper review with PDF upload, customizable parameters, multilingual support, and a responsive, animated UI built with React, Tailwind CSS, and integrated with OpenAI/Claude’s API.\",github:\"https://github.com/nohairblingbling/paper-review-assistant\"//website: \"\",\n},{img:\"interview\",title:\"Interview Assistant\",description:\"Developed a cross-platform Electron app for real-time interview response suggestions, integrating speech-to-text, GPT-based intelligent answers, and personalized content management, with privacy-focused local data processing.\",github:\"https://github.com/nohairblingbling/Interview-Assistant\"//website: \"\",\n},{img:\"dcd\",title:\"Teaching DCD Children How to Move Using AR\",description:\"Developed a web-based AR app for children with DCD, featuring a user-friendly UI, WebXR for 3D training, MediaPipe for real-time motion detection, and a supportive scoring system to enhance motor skills.\"//github: \"https://github.com/nohairblingbling/Interview-Assistant\",\n//website: \"\",\n}];var contactConfig={YOUR_EMAIL:\"yjia8942@uni.sydney.edu.au\",YOUR_FONE:\"-\",description:\"- \",// creat an emailjs.com account\n// check out this tutorial https://www.emailjs.com/docs/examples/reactjs/\nYOUR_SERVICE_ID:\"service_id\",YOUR_TEMPLATE_ID:\"template_id\",YOUR_USER_ID:\"user_id\"};var socialprofils={github:\"https://github.com/nohairblingbling\",//   facebook: \"https://facebook.com\",\n//scholar: \"https://scholar.google.com/citations?user=POepUzkAAAAJ&hl=en\",\n//linkedin: \"https://www.linkedin.com/in/seonghee-lee/\",\ninstagram:\"https://www.instagram.com/lorcanxoo/\"};export{meta,dataabout,dataportfolio,researchexperience,workexperience,worktimeline,services,introdata,contactConfig,socialprofils,projectportfolio,logotext,awards};","map":{"version":3,"names":["logotext","meta","title","description","introdata","dataabout","aboutme","worktimeline","jobtitle","where","date","skills","name","value","services","period","awards","workexperience","researchexperience","dataportfolio","img","authors","conference","notes","code","bold","doi","projectportfolio","github","contactConfig","YOUR_EMAIL","YOUR_FONE","YOUR_SERVICE_ID","YOUR_TEMPLATE_ID","YOUR_USER_ID","socialprofils","instagram"],"sources":["/Users/duskandwine/MyProject/(Old)Personalweb/new/shljessie.github.io/src/content_option.js"],"sourcesContent":["const logotext = \"Yuzhuo Jia\";\nconst meta = {\n  title: \"Yuzhuo Jia\",\n  description: \"I'm Yuzhuo Jia\",\n};\n\nconst introdata = {\n  title: \"Yuzhuo Jia\",\n//   animated: {\n//     first: \"[]\",\n//     second: \"[]\",\n//   },\n//   description:\n//     \"In the past, I was a Research Assistant at the KAIST Interaction Lab (KIXLAB) developing a Generative Agent for Programming Education. My research interests are at the intersection of Human-AI Interaction and applied Machine Learning.\",\n//   description_two:\n//     \"  I am currently a first year Computer Science (MS) student at Stanford and I did my undergrad at Cornell studying Information Science. I have received grants and scholarships for my research like the Robert S Ann Morley Research Grant and the Gwanjeong Scholarship for my Master's Studies.\",\n//   your_img_url: \"\",\n};\n\nconst dataabout = {\n  title: \"Research Interests\",\n  aboutme:\n    \"My research interests focus on interdisciplinary studies, with a particular emphasis on exploring how deep learning, computer vision, or LLM technologies can be integrated with diverse fields. I aim to develop innovative, socially conscious research and tools that not only contribute to academic advancement but also address real-world societal challenges. My goal is to harness the power of AI to create solutions that are both technologically advanced and ethically responsible, ensuring their positive impact across different communities and disciplines.\",\n};\nconst worktimeline = [\n  {\n    jobtitle: \"University of Sydney\",\n    where: \"Computer Science (MS)\",\n    date: \"Feb 2023 - Mar 2025\",\n  },\n  {\n    jobtitle: \"Nanfang College of Sun Yat-sen University\",\n    where: \"Computer Science and Technology (BS)\",\n    date: \"Sep 2017 - June 2021\",\n  },\n];\n\nconst skills = [\n  {\n    name: \"Python\",\n    value: 90,\n  },\n  {\n    name: \"Djano\",\n    value: 85,\n  },\n  {\n    name: \"Javascript\",\n    value: 80,\n  },\n  {\n    name: \"React\",\n    value: 60,\n  },\n  {\n    name: \"Jquery\",\n    value: 85,\n  },\n];\n\nconst services = [\n  {\n    title: \"SDG AI Lab - Software Engineer\",\n    period: \"March 2023 - May 2023\",\n    description:\n      \"Development of the Digital Technologies Radar : a Frontier Technology Radar for Disaster Risk Reduction (FTR4DRR), which allows for the systematic tracking and understanding of frontier technologies as they are developed. https://github.com/SDG-AI-Lab/Digital_Technologies_Radar\",\n  },\n  {\n    title: \"Inspirit AI - AI/ML Instructor\",\n    period: \"March 2020 - \",\n    description:\n      \"Conducted lectures on Neural Networks, Computer Vision, Deep Learning, Reinforcement Learning and helped highschool students work on programming ML Models\",\n  },\n  {\n    title: \"Cornell Data Science - Insights Team\",\n    period: \"Janurary 2020 - December 2022 \",\n    description:\n      \"Insights Team - Conducted and led Data Science/Machine Learning Projects, Conducted lectures on Neural Networks for Freshman Onboarding INFO 1998 ML lectures \",\n  },\n];\n\nconst awards = [\n  {\n    title: \"Gwanjeong Educational Foundation Scholarship - Masters Degree\",\n    period: \"Sep 2023 - June 2025\",\n  },\n  {\n    title:\n      \"ACM/IEEE Human Robot Interaction (HRI 2023) - Best Student Paper Award\",\n    period: \"March 2022\",\n  },\n  {\n    title: \"Robert S Ann Morley Research Grant - Cornell University\",\n    period: \" December 2021 \",\n  },\n];\n\nconst workexperience = [\n  {\n    title: \"[Motional] Robotics Research Engineer\",\n    period: \"Sep 2022 - Dec 2022\",\n    description:\n      \"Research on identification of Autonomous Vehicle Lane Change key parameters and metrics in dynamic road environments interacting with other agents. Published and first authored 2 papers to ACM/IEEE HRI 2023\",\n  },\n  {\n    title: \"[Harvard Berkman Klein Center] Software Engineer\",\n    period: \"May 2023 - August 2023\",\n    description:\n      \"Developed Software for dynamic text annotation and page navigation on H2O, an open-casebook platform (React, Django). Conducted Research on Digital Reading Interaction Software and published paper to ACM/IEEE CHI 2023\",\n  },\n  {\n    title: \"[Cochl. AI] Software Engineer\",\n    period: \"Nov 2020 - Feb 2021 \",\n    description:\n      \"Integrated non-verbal sound recognition AI into Mercedes Benz User Interface. Full-stack development using React, Javascript, SocketIO, Docker. Developed and demonstrated a working prototype of Emotional Sound Recognition within Benz Cars to the Mercedes Benz Team - Presentation at Benz conference in Germany\",\n  },\n];\n\nconst researchexperience = [\n    {\n        title: \"BiFocalNet: Dual-Branch Architecture for Enhanced Remote Sensing Segmentation\",\n        period: \"Sep 2023 – Jul 2024\",\n        description:\n          \"Developed BiFocalNet, a deep learning architecture for remote sensing segmentation, achieving a 3.062% improvement in mean IoU on the GID dataset. Designed a parallelized encoder combining EfficientNetV2 and Pyramid Vision Transformer, integrated via Cross-Fusion and SuperASPP modules for enhanced multi-scale context modeling. Demonstrated superior performance in key categories, with 3.279% and 3.514% improvements in 'Forest' and 'Built-up' segmentation.\",\n      },\n\n    {\n        title: \"FODAP Graph for Enhanced Medical Imaging Narrative Generation\",\n        period: \"Mar 2023 – May 2024\",\n        description:\n        \"Co-designed a MedSAM-based visual encoder with Vision Transformer (ViT) architecture, processing 512x512 medical images for high-quality feature representation. Simplified model by removing the MLP neck and optimizing patch embeddings. Implemented a feature reduction strategy to improve generalization across datasets. Conducted comparative experiments, showing MedSAM's superior performance in medical imaging, and contributed to the Graph-Enhanced Attention (GEA) mechanism for more accurate medical report generation.\",\n    },\n\n{\n  title: \"A Study on Corn Pest Detection Based On Improved YOLOv7\",\n  period: \"Dec 2023 – Mar 2024\",\n  description:\n    \"Developed SPD-YOLOv7, an enhanced model for corn pest detection with 98.38% accuracy, 99.51% recall, and 99.4% mAP@0.5, outperforming YOLOv7. Introduced SPD-Conv to improve small object detection and ELAN-W with CBAM attention for better feature extraction in complex backgrounds. Conducted ablation experiments to validate model improvements, especially for small pest detection.\",\n},\n];\n\nconst dataportfolio = [\n  {\n    img: \"BiFocalNet\",\n    title:\n      \"BiFocalNet: Dual-Branch Architecture for Enhanced Remote Sensing Segmentation\",\n    authors:\n      \"Yuzhuo Jia\",\n    conference:\n      \"IEEE Transactions on Geoscience and Remote Sensing\",\n    //doi: \"https://doi.org/10.48550/arXiv.2408.10240\",\n    //video: \"https://www.youtube.com/watch?v=tJUqjjwSxPs\",\n    notes: \"Under Revision\",\n    code: \"Code Coming Soon\",\n  },\n  {\n    img: \"bibm1\",\n    title:\n      \"FODAP Graph for Enhanced Medical Imaging Narrative Generation: Adaptive Differentiation of Normal and Abnormal Attributes\",\n    authors: [\n      { name: \"Kai Shu\", bold: true },\n      { name: \"Yuzhuo Jia\", bold: true },\n      { name: \"Ziyang Zhang\", bold: false },\n      { name: \"Jiechao Gao\", bold: false }\n    ],\n    conference: \"International Conference on Bioinformatics and Biomedicine (BIBM 2024)\",\n    doi: \"https://www.arxiv.org/abs/2409.03947\",\n  },\n  {\n    img: \"yolo5\",    \n    title:\n      \"Pedestrian behavior detection and traffic violation recognition based on YOLOv5\",\n    authors: \"Yuzhuo Jia\",\n    conference:\n      \"International Conference on Image Processing and Intelligent Control\",\n    doi: \"https://doi.org/10.1117/12.3038591\",\n  },\n];\n\nconst projectportfolio = [\n  {\n    img: \"paper\",\n    title: \"Paper Review Assistant\",\n    description:\n      \"Developed a Next.js web app utilizing AI for academic paper review with PDF upload, customizable parameters, multilingual support, and a responsive, animated UI built with React, Tailwind CSS, and integrated with OpenAI/Claude’s API.\",\n    github: \"https://github.com/nohairblingbling/paper-review-assistant\",\n    //website: \"\",\n  },\n  {\n    img: \"interview\",\n    title: \"Interview Assistant\",\n    description:\n      \"Developed a cross-platform Electron app for real-time interview response suggestions, integrating speech-to-text, GPT-based intelligent answers, and personalized content management, with privacy-focused local data processing.\",\n    github: \"https://github.com/nohairblingbling/Interview-Assistant\",\n    //website: \"\",\n  },\n\n  {\n    img: \"dcd\",\n    title: \"Teaching DCD Children How to Move Using AR\",\n    description:\n      \"Developed a web-based AR app for children with DCD, featuring a user-friendly UI, WebXR for 3D training, MediaPipe for real-time motion detection, and a supportive scoring system to enhance motor skills.\",\n    //github: \"https://github.com/nohairblingbling/Interview-Assistant\",\n    //website: \"\",\n  },\n\n];\n\nconst contactConfig = {\n  YOUR_EMAIL: \"yjia8942@uni.sydney.edu.au\",\n  YOUR_FONE: \"-\",\n  description: \"- \",\n  // creat an emailjs.com account\n  // check out this tutorial https://www.emailjs.com/docs/examples/reactjs/\n  YOUR_SERVICE_ID: \"service_id\",\n  YOUR_TEMPLATE_ID: \"template_id\",\n  YOUR_USER_ID: \"user_id\",\n};\n\nconst socialprofils = {\n  github: \"https://github.com/nohairblingbling\",\n//   facebook: \"https://facebook.com\",\n  //scholar: \"https://scholar.google.com/citations?user=POepUzkAAAAJ&hl=en\",\n  //linkedin: \"https://www.linkedin.com/in/seonghee-lee/\",\n  instagram: \"https://www.instagram.com/lorcanxoo/\",\n};\nexport {\n  meta,\n  dataabout,\n  dataportfolio,\n  researchexperience,\n  workexperience,\n  worktimeline,\n  services,\n  introdata,\n  contactConfig,\n  socialprofils,\n  projectportfolio,\n  logotext,\n  awards,\n};\n"],"mappings":"AAAA,GAAMA,SAAQ,CAAG,YAAY,CAC7B,GAAMC,KAAI,CAAG,CACXC,KAAK,CAAE,YAAY,CACnBC,WAAW,CAAE,gBACf,CAAC,CAED,GAAMC,UAAS,CAAG,CAChBF,KAAK,CAAE,YACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAED,GAAMG,UAAS,CAAG,CAChBH,KAAK,CAAE,oBAAoB,CAC3BI,OAAO,CACL,gjBACJ,CAAC,CACD,GAAMC,aAAY,CAAG,CACnB,CACEC,QAAQ,CAAE,sBAAsB,CAChCC,KAAK,CAAE,uBAAuB,CAC9BC,IAAI,CAAE,qBACR,CAAC,CACD,CACEF,QAAQ,CAAE,2CAA2C,CACrDC,KAAK,CAAE,sCAAsC,CAC7CC,IAAI,CAAE,sBACR,CAAC,CACF,CAED,GAAMC,OAAM,CAAG,CACb,CACEC,IAAI,CAAE,QAAQ,CACdC,KAAK,CAAE,EACT,CAAC,CACD,CACED,IAAI,CAAE,OAAO,CACbC,KAAK,CAAE,EACT,CAAC,CACD,CACED,IAAI,CAAE,YAAY,CAClBC,KAAK,CAAE,EACT,CAAC,CACD,CACED,IAAI,CAAE,OAAO,CACbC,KAAK,CAAE,EACT,CAAC,CACD,CACED,IAAI,CAAE,QAAQ,CACdC,KAAK,CAAE,EACT,CAAC,CACF,CAED,GAAMC,SAAQ,CAAG,CACf,CACEZ,KAAK,CAAE,gCAAgC,CACvCa,MAAM,CAAE,uBAAuB,CAC/BZ,WAAW,CACT,wRACJ,CAAC,CACD,CACED,KAAK,CAAE,gCAAgC,CACvCa,MAAM,CAAE,eAAe,CACvBZ,WAAW,CACT,4JACJ,CAAC,CACD,CACED,KAAK,CAAE,sCAAsC,CAC7Ca,MAAM,CAAE,gCAAgC,CACxCZ,WAAW,CACT,gKACJ,CAAC,CACF,CAED,GAAMa,OAAM,CAAG,CACb,CACEd,KAAK,CAAE,+DAA+D,CACtEa,MAAM,CAAE,sBACV,CAAC,CACD,CACEb,KAAK,CACH,wEAAwE,CAC1Ea,MAAM,CAAE,YACV,CAAC,CACD,CACEb,KAAK,CAAE,yDAAyD,CAChEa,MAAM,CAAE,iBACV,CAAC,CACF,CAED,GAAME,eAAc,CAAG,CACrB,CACEf,KAAK,CAAE,uCAAuC,CAC9Ca,MAAM,CAAE,qBAAqB,CAC7BZ,WAAW,CACT,gNACJ,CAAC,CACD,CACED,KAAK,CAAE,kDAAkD,CACzDa,MAAM,CAAE,wBAAwB,CAChCZ,WAAW,CACT,2NACJ,CAAC,CACD,CACED,KAAK,CAAE,+BAA+B,CACtCa,MAAM,CAAE,sBAAsB,CAC9BZ,WAAW,CACT,uTACJ,CAAC,CACF,CAED,GAAMe,mBAAkB,CAAG,CACvB,CACIhB,KAAK,CAAE,+EAA+E,CACtFa,MAAM,CAAE,qBAAqB,CAC7BZ,WAAW,CACT,4cACJ,CAAC,CAEH,CACID,KAAK,CAAE,+DAA+D,CACtEa,MAAM,CAAE,qBAAqB,CAC7BZ,WAAW,CACX,2gBACJ,CAAC,CAEL,CACED,KAAK,CAAE,yDAAyD,CAChEa,MAAM,CAAE,qBAAqB,CAC7BZ,WAAW,CACT,8XACJ,CAAC,CACA,CAED,GAAMgB,cAAa,CAAG,CACpB,CACEC,GAAG,CAAE,YAAY,CACjBlB,KAAK,CACH,+EAA+E,CACjFmB,OAAO,CACL,YAAY,CACdC,UAAU,CACR,oDAAoD,CACtD;AACA;AACAC,KAAK,CAAE,gBAAgB,CACvBC,IAAI,CAAE,kBACR,CAAC,CACD,CACEJ,GAAG,CAAE,OAAO,CACZlB,KAAK,CACH,2HAA2H,CAC7HmB,OAAO,CAAE,CACP,CAAET,IAAI,CAAE,SAAS,CAAEa,IAAI,CAAE,IAAK,CAAC,CAC/B,CAAEb,IAAI,CAAE,YAAY,CAAEa,IAAI,CAAE,IAAK,CAAC,CAClC,CAAEb,IAAI,CAAE,cAAc,CAAEa,IAAI,CAAE,KAAM,CAAC,CACrC,CAAEb,IAAI,CAAE,aAAa,CAAEa,IAAI,CAAE,KAAM,CAAC,CACrC,CACDH,UAAU,CAAE,wEAAwE,CACpFI,GAAG,CAAE,sCACP,CAAC,CACD,CACEN,GAAG,CAAE,OAAO,CACZlB,KAAK,CACH,iFAAiF,CACnFmB,OAAO,CAAE,YAAY,CACrBC,UAAU,CACR,sEAAsE,CACxEI,GAAG,CAAE,oCACP,CAAC,CACF,CAED,GAAMC,iBAAgB,CAAG,CACvB,CACEP,GAAG,CAAE,OAAO,CACZlB,KAAK,CAAE,wBAAwB,CAC/BC,WAAW,CACT,2OAA2O,CAC7OyB,MAAM,CAAE,4DACR;AACF,CAAC,CACD,CACER,GAAG,CAAE,WAAW,CAChBlB,KAAK,CAAE,qBAAqB,CAC5BC,WAAW,CACT,mOAAmO,CACrOyB,MAAM,CAAE,yDACR;AACF,CAAC,CAED,CACER,GAAG,CAAE,KAAK,CACVlB,KAAK,CAAE,4CAA4C,CACnDC,WAAW,CACT,6MACF;AACA;AACF,CAAC,CAEF,CAED,GAAM0B,cAAa,CAAG,CACpBC,UAAU,CAAE,4BAA4B,CACxCC,SAAS,CAAE,GAAG,CACd5B,WAAW,CAAE,IAAI,CACjB;AACA;AACA6B,eAAe,CAAE,YAAY,CAC7BC,gBAAgB,CAAE,aAAa,CAC/BC,YAAY,CAAE,SAChB,CAAC,CAED,GAAMC,cAAa,CAAG,CACpBP,MAAM,CAAE,qCAAqC,CAC/C;AACE;AACA;AACAQ,SAAS,CAAE,sCACb,CAAC,CACD,OACEnC,IAAI,CACJI,SAAS,CACTc,aAAa,CACbD,kBAAkB,CAClBD,cAAc,CACdV,YAAY,CACZO,QAAQ,CACRV,SAAS,CACTyB,aAAa,CACbM,aAAa,CACbR,gBAAgB,CAChB3B,QAAQ,CACRgB,MAAM"},"metadata":{},"sourceType":"module","externalDependencies":[]}